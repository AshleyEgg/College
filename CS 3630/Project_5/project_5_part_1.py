# -*- coding: utf-8 -*-
"""Project_5_Part_1_Instructions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hrOCMQR61oHexxqaOxnhof9tR7CqBw1Y

# Project 5: Vision (Part 1)

Due Date: Monday, March 23, 2020 @ 11:59 P.M.

*(Please note that we recommend students complete Part 1 before Part 2 is released (i.e. March 9). This will give us time to resolve any hardware issues you may face in Part 1 and it will you give you sufficient time to finish Part 2 in time.)*

Student #1 Name: Ashley Eggart

Student #2 Name: Yumin Jeong

Student #3 Name: Jennifer Lu

Student #4 Name: Andrew Kristanto

In this project, you will be capturing images using the duckiebot camera while moving forward on a "road" with lanes in part 1, and then use those images to get the orientation of the robot on the road. This pose can then be used for self-driving applications such as lane detection and following.

## Code that we will be working with

We will be working with two python scripts primarily, that you will run without much of any modifications.

1) **test_image_quality.py** 

This script will capture an image using the duckiebot camera. This will be used to make sure the duckiebot camera is functional and that the focal length of the camera is adjusted to get a clear picture

2) **move_forward_and_capture_images.py** 

This script is similar to the move_in_line.py from project 3 in that it will move the robot forward, but it will also capture images with the camera while moving forward. These images will be used in Part-2 of the project.

##SETUP

We are assuming that project 3 was successfully completed and:

a) The robot has its SD card flashed

b) You can SSH into the duckiebot through the Chrome Shell

c) You can command the duckiebot to move relatively straight using the motors.

Students will be working in groups of 2 teams (i.e. 4 students per group) and the students need to refer to this sheet below to see which team they've been paired with. We are doing this to increase the chance of groups working with duckiebots that work correctly. Below is the link to the sheet listing team pairs:

https://drive.google.com/file/d/1sS5btopwpchRhY5tD6-70TqP8LkjjpSg/view?usp=sharing

You can reach out to your assigned groupmates through the Canvas People tool, or look up emails through directory.gatech.edu.
If you have issues contacting your assigned team, scheduling issues with the team you were paired with, or would like to pair up with another team, please let the TAs know during OH or email Chaitya (cs@gatech.edu) directly, and we can try to move the teams around accordingly. **Please do not post about team changes on piazza.**

**Before asking to switch, please be sure of the following:**
* Make sure you have at least one working robot between both teams before asking to switch.
* Make sure both 4-person teams are ok with the switch

###Connect to the duckie bot:
Turn on the battery of the duckiebot so you can connect to the duckiebot

SSH into your duckiebot from the chrome shell using the instructions from "Software instructions" ppt https://docs.google.com/presentation/d/1jAONDBIMahUPJKV61F9lSqVBLig5t9Q3k-OZBJAri3U/edit#slide=id.g6e6e9ff1eb_0_44

slide 12: "9. SSHing into your duckie from Chrome shell"

When you [ssh](https://en.wikipedia.org/wiki/Secure_Shell) into the DuckeiBot through the chrome shell, you should be in the /home/duckie folder. 

Use the command   
`pwd`  
in the shell to verify your current path is `/home/duckie` 

###Clone from github the source for for project 5 and run the docker image:


We cloned the 3630 Assignments repository into a folder called "project3" last time. If you want, you can rename the project3 folder to "projects" to clean up the directory structure a bit. You can do this using the command `mv project3 projects`. Following this, run

```
cd projects
git pull
```
to pull in the project 5 starter code.

When/If it asks for your username and password, enter your gatech github credentials.

Alternatively, if you want to clone the starter code repository fresh, you can simply run this command in the /home/duckie directory.
```
git clone https://github.gatech.edu/CS3630-TAs/CS3630-Assignments.git projects
```
 
Then, pull the docker image that contains the environment to execute the project 5 ROS package.
```
docker pull alexma3312/cs3630-project:v6
```  
To check if the image was successfully downloaded, do
```
docker images
```
to see all docker images. You should see an image named `alexma3312/cs3630-project:v6`. v6 is the tag of the image. 

Note, we used v5 for project 3. This project requires v6. Some of the commands later in the instructions may not work if you are still using v5.


Next, run the docker image with the following command :

```
docker run -it --name project5 -v /home/duckie/projects/project5/src/project/packages:/code/catkin_ws/src/project/packages --rm --net=host alexma3312/cs3630-project:v6 /bin/bash
```

You may see a message saying `VEHICLE_NAME is not set`. Ignore this as this is not an error.  
After this step you should be inside the docker container. The user of the shell will change from `duckie@duckieXXX` to `root@duckieXXX`.  
To check if you are in the container, do
```
lsb_release -a
```
You will see `Distributor ID:	Ubuntu` if you are in the container.

###See the python scripts you will be using

For this project, you will use the python scripts test_image_quality.py and move_forward_and_capture_images.py. The above `docker run` command gives you root access to the running docker container.
The file path in the docker container is `/code/catkin_ws/src/project/packages/project5/src/test_image_quality.py` for example.  
You won't have to edit the python files, but if you did, you have to use the built-in text editor called **nano**.  

Make sure to follow the instructions carefully. If you encounter any problems, post questions on Piazza or come to office hours to get help.

## Running the code

Now that you are connected to the DuckieBot using the Chrome shell, you are ready to run the scripts!

For more information about the way the internal structure of the DuckieBot Raspberry Pi, feel free to look at the project 3 instructions, which provide some more details.

To run code, from inside the docker container, do:
```
rosrun project5 filename.py
```
We will look in more detail at the two scripts in following instructions.

The code will run, and output the saved image files to the folder `/code/catkin_ws/src/project/packages/project5/src/saved_images/`.
Outside the docker container, this directory will be `/home/duckie/projects/project5/src/project/packages/project5/src/saved_images/`

## **NOTE: Place the bot behind the yellow tape for all the experiments. This will be the start point that represents the origin.**


## 1. Test the camera and get the focal length adjusted using test_image_quality.py

In this part, you will work with the test_image_quality.py python script located at `/code/catkin_ws/src/project/packages/project5/src/test_image_quality.py`. This script will capture an image using the duckiebot camera. This will be used to make sure the duckiebot camera is functional and that the focal length of the camera is adjusted to get a clear picture.

###Run the test_image_quality.py script to get an image

From within the docker container, run the test_image_quality.py through the following:

```
rosrun project5 test_image_quality.py -hostname duckieXXX
```

where XXX is your team/robot number.

If run successfully, an image should be generated in the `saved_images` directory called `test_img.png`

To go to the directory with the `saved_images` folder, do the following:

```
cd /code/catkin_ws/src/project/packages/project5/src
```

###Transfer the image to your local computer using scp

Copy the image `test_img.png` to your local computer using the instructions in  section “Instructions to copy images from duckiebot to computer to view the images”

View the image and see if its blurry, and adjust focal length accordingly. You can adjust the focal length by rotating the camera clockwise or anti-clockwise. You might have to adjust the focal length and check the image multiple times, until you get a sufficiently clear image.

###Instructions to copy images from duckiebot to computer to view the images

If you have windows, Download putty (https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) so that you can use the scp command in your terminal. If you're on Mac or Linux, you can use your default terminal, or your favorite ssh client.

Run the command below in your local terminal (not chrome shell). To transfer over a folder instead of a file, add “-r” tag after scp. 

Format of command:

Scp {-r tag optional to indicate folder} {src} {destination. Can put  a “.” to indicate destination is current folder}

Example:
```
scp -r duckie@duckieXXX.local:/home/duckie/projects/project5/src/project/packages/project5/src/saved_images/ .

scp duckie@duckieXXX.local:/home/duckie/projects/project5/src/project/packages/project5/src/saved_images/test_img.png .
```
where XXX with your team/robot number.

Once you've verified that your camera focal length is set correctly, you need to find the value of the focal length using the following command:

```
rostopic echo /duckieXXX/camera_node/camera_info
```
where XXX with your team/robot number.
Look for 'K' in the camera information being printed. Here, K stands for the Internal camera matrix. K is a 3x3 matrix.

$$K = \begin{bmatrix} 
  f_x & a & u_0 \\ 
  0 & f_y & v_0 \\
  0 & 0 & 1
  \end{bmatrix}
$$

You will observe that fx and fy are almost equal. Calculate the mean of fx and fy to get the focal length and enter it in proj5_part1_report_template.pptx file along with a screenshot of K matrix from the command line.

Now, let's move on to the next step to gather 20 images that will be used in part 2.

##2. Run the move forward and capture code [30 points]

After making sure the image isn’t blurry, we will now run the “move_forward_and_capture_images.py” file that will move the robot forward while capturing images at 6 frames per second.

Put the robot at the start point of the runway mat in the robotics lab. Place the robot in the center of the X-axis facing straight, parallel to the road lanes. 

Mark the initial starting position of the robot by placing a piece of colored tape across the front two wheels so it is perpendicular to the wheels.

Now we can run the robot forward.

To run the program from within the docker container run:
```
rosrun project5 move_forward_and_capture_images.py -hostname {HOSTNAME} -duration {RUNTIME} -vel {DESIRED VELOCITY} -trim {TRIM}
```

The {HOSTNAME} will be in the format `duckieXXX`, where XXX is the group number. In {DESIRED_VELOCITY} and {TRIM} put your desired linear velocity and trim value. The trim value is adjusted from 0 in order to get the robot to move straight.

The robot will stop moving after the set {RUNTIME}.

You should target the robot move 1 meter (almost the length of 2 duckietown tiles) in 4 seconds, and collect at least 20 images. The distance will be marked on the duckietown tiles in CCB 030. Feel free to tune the parameters until your robot moves the distance of 1 meter. Keep in mind that the duckiebot collects 6 images/sec.

We recommend {RUNTIME} = 4 seconds and {DESIRED VELOCITY} = 0.3. 

Make sure the robot moves forward in a straight line as desired and saves at least 20 images. View the images using the instructions in "Instructions to copy images from duckiebot to computer to view the images" section, and make sure the images are clear. 

Once you have 20 images, upload the folder with the images on your Google Drive and provide the following in the proj5_part1_report_template.pptx file: 
1. A screenshot of one of the 20 images captured by the camera.
2. Google Drive link to the folder of images (Remember to make sure that the folder is viewable by anyone with the link)

###Capture ground truth of robot trajectory

You will need to gather information on how the robot's pose changed during your data gathering process. Do this by measuring with a ruler or measuring tape (there should be some available in the TA lab). 

1. Once the bot stops after running move_forward_and_capture_images.py code, mark the final position of the robot using the method we did previously. Specifically,  place a piece of colored tape across the front two wheels so it is perpendicular to the wheels. 
2. Measure coordinates - Use the measuring tape to record the change in x and y of the end point with respect to the start point.( start point is represented using yellow tape).
3. Measure angle - At the end position, measure the angle of the camera with respect to vertical line parallel to the lane markings. Suggestion is to use a protractor.

Enter the (x,y,theta) of the end point in proj5_part1_report_template.pptx file with **units in centimeters**.

**Note: Remove the colored tape once done in order to avoid confusion for the next team. Also, DO NOT remove the yellow/white tape which are the lanes.**

This information will be used as ground truth for our calculations in Part 2 of the lab.

### Measure height of the camera 
Measure the height (vertical distance) of the center of the camera lens from the ground and enter the value in proj5_part1_report_template.pptx (**units in centimeters**)

### Measure the pitch of the camera 
Measure the pitch of the camera from the medial point (theta angle difference from camera facing completely straight. Measure in degrees using protractor in lab). This won't be reported in the reflection ppt, but save it for use in part 2.

**Note: Before leaving, get the following reviewed by the TA:.**

1) Check if images doesn't look blurry

2) check if path looks relatively straight

3) Check x,y, theta. Make sure y is about 1 meter.

4) Pitch of the camera

5) height of the camera lens

6) Camera matrix

7) There are 20 images captured

## 3. Reflection [50 points]

Answer the questions in the proj5_part1_report_template.pptx. 
You can find the pptx file in the files tab on Canvas.  
Save the file as a PDF and rename it to LASTNAME1_LASTNAME2_LASTNAME3_LASTNAME4_reflection1.pdf

## Rubric
- 50 pts: Successfully gathered 20 images (saved_images.zip). Upload zip to canvas
- 50 pts: reflection writeup

## Submission Details
### Deliverables

You will have these two files to submit for part 1.  
- saved_images.zip - A zip of your 20 images captured from running `move_forward_and_capture_images.py`
- LASTNAME1_LASTNAME2_LASTNAME3_LASTNAME4_reflection1.pdf: The reflection slides converted to PDF form. 

See submission details in part 2 for the final submission format. Only one person per 4-person group should upload the submission.
"""